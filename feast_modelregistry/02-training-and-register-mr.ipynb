{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70056bc7-87a8-4ad9-bb7c-9676464c5932",
   "metadata": {},
   "source": [
    "# Train Models using Feast historical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e8790-c01f-400f-b7d6-42fe30a85450",
   "metadata": {},
   "source": [
    "* Collect historical features from Feast\n",
    "* Rebuild the MNIST dataset from the features\n",
    "* Train different models using the dataset\n",
    "* Register models using Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc0d45-4c06-4458-bc9a-43e61129c875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!cat requirements.txt\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install --no-deps --ignore-requires-python \"https://github.com/opendatahub-io/ml-metadata/releases/download/v1.14.0%2Bremote.1/ml_metadata-1.14.0+remote.1-py3-none-any.whl\" # need a Python 3.11 compatible version\n",
    "!pip install --no-deps --ignore-requires-python \"model-registry==0.1.2\" # ignore dependencies because of the above override"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae2270-0256-4c87-a1b5-a989cea70ec4",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4918011-4fee-4c97-be06-e5800716efe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 11:41:11.030648: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-18 11:41:11.960976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "from feast import FeatureStore\n",
    "from IPython.display import Markdown as md\n",
    "from model_registry import ModelRegistry\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sqlalchemy import create_engine, MetaData, Table, select, Column, Integer, DateTime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79b0dfa-8164-4277-952e-d137ba58cd20",
   "metadata": {},
   "source": [
    "**Note**: update this value to match the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d767e338-2334-4d26-a5d8-94e46361c357",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: REPO_PATH=mnist_demo/feature_repo/\n"
     ]
    }
   ],
   "source": [
    "%env REPO_PATH=mnist_demo/feature_repo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6e6982-8508-4040-ad5f-e42ddbcfed3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['accesskey'] = 'minio'\n",
    "os.environ['secretkey'] = 'minio123'\n",
    "s3url = 'http://minio-service.feast.svc.cluster.local:9000'\n",
    "bucket_name = 'feast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "655fefb2-ccfc-4992-a7b6-c57dbd17ea1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psqlHost = 'postgresql.feast.svc.cluster.local'\n",
    "psqlPort = 5432\n",
    "psqlUsername = 'feast'\n",
    "psqlPassword = 'feast'\n",
    "psqlDb = 'feast'\n",
    "psqlSchema = 'feast'\n",
    "\n",
    "mnistTableName = 'mnist_source'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8454f520-ce93-4a6b-ae7e-eb02e420a4fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reusable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41925691-0ea5-4fbb-bf9d-7cadfc480363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simpleNN():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape=(28,28)))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model, 'simple_NN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4358eb16-4b9f-480e-b190-8150e1360380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convolutedNN():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), input_shape=(28, 28, 1)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=64, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model, 'convolutedNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de13e58-c58d-42b0-a70b-a25ed352627f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluateModelAccuracy(model, model_name):\n",
    "    y_prob = model.predict(X_test)\n",
    "    y_pred = y_prob.argmax(axis=1)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    print(f'Prediction accuracy for model `{model_name}` is: {round(accuracy * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f03cc35-90bf-4163-9be7-00e957a05ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testModelForSample(model, sample_id):\n",
    "    plt.imshow(X_test[sample_id], cmap=\"Greys\")\n",
    "    plt.title(f'X_test[{sample_id}]:')\n",
    "    plt.show()\n",
    "    prediction = model.predict(X_test[sample_id].reshape(1,28,28)).argmax(axis=1)[0]\n",
    "    print(f'prediction for sample {sample_id} is: ', prediction)\n",
    "    print(f'**Note**: the calculated prediction {prediction} must match the number plotted above. If not, the test failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a240deb1-4ba8-46b2-9160-72e86607f58f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def saveModel(model, model_name):\n",
    "    input_signature = [tf.TensorSpec([1, 28, 28], tf.double, name='x')]\n",
    "    onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature, opset=12)\n",
    "    file_name = f\"{model_name}.onnx\"\n",
    "    onnx.save(onnx_model, file_name)\n",
    "    print(f\"Saved as {file_name}\")\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd5963e-fabb-40ac-a002-2c7946955d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testModelFromFileForSample(file_name, sample_id):\n",
    "    plt.imshow(X_test[sample_id], cmap=\"Greys\")\n",
    "    plt.title(f'X_test[{sample_id}]:')\n",
    "    plt.show()\n",
    "    model_onnx = onnx.load(file_name)\n",
    "    output = [node.name for node in model_onnx.graph.output]\n",
    "    print(output)\n",
    "\n",
    "    sess = ort.InferenceSession(file_name)\n",
    "    results_ort = sess.run([output[0]], {'x': X_test[sample_id].reshape(1,28,28)})\n",
    "    prediction = results_ort[0].argmax(axis=1)[0]\n",
    "    print(f'**Note**: the calculated prediction {prediction} must match the number plotted above. If not, the test failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb617aaa-d045-44dc-aa74-6c300a1ad5b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def storeTrainedModel(model, model_name, file_name):\n",
    "    registeredmodel_name = \"mnist\"\n",
    "    version_name = \"v.\"+model_name+\".\"+datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    print(f\"Will be using: {registeredmodel_name}:{version_name} in the remainder of this task\")\n",
    "\n",
    "    # Updated config for https://play.min.io:9443/\n",
    "    s3 = boto3.resource(\n",
    "        service_name='s3',\n",
    "        # region_name='default',\n",
    "        aws_access_key_id=os.environ['accesskey'],\n",
    "        aws_secret_access_key=os.environ['secretkey'],\n",
    "        # use_ssl=False,\n",
    "        endpoint_url=s3url,\n",
    "        # config=boto3.session.Config(signature_version='s3v4'),\n",
    "        verify=False\n",
    "    )\n",
    "\n",
    "    odh_secret_name = f'aws-connection-{bucket_name}'\n",
    "    in_bucket_path = version_name\n",
    "    in_bucket_target = f'{in_bucket_path}/{file_name}'\n",
    "    full_bucket_target = f's3://{bucket_name}/{in_bucket_target}'\n",
    "\n",
    "    my_bucket = s3.Bucket(bucket_name)\n",
    "    my_bucket.upload_file(file_name, in_bucket_target)\n",
    "\n",
    "    print(f\"Objects in the {bucket_name} bucket:\")\n",
    "    for obj in my_bucket.objects.filter():\n",
    "        print(obj.key)\n",
    "    return (registeredmodel_name, version_name, odh_secret_name, in_bucket_path,in_bucket_target, full_bucket_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f58bc62-59ef-49dc-8201-f24daef451bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def registerToModelRegistry(\n",
    "    registeredmodel_name,\n",
    "    version_name,\n",
    "    odh_secret_name,\n",
    "    in_bucket_path,\n",
    "    in_bucket_target,\n",
    "    full_bucket_target):\n",
    "    registry = ModelRegistry(server_address=\"modelregistry-sample.feast.svc.cluster.local\", port=9090, author=\"feast-dev@redhat.com\")\n",
    "\n",
    "    rm = registry.register_model(registeredmodel_name,\n",
    "                                    full_bucket_target,\n",
    "                                    model_format_name=\"onnx\",\n",
    "                                    model_format_version=\"1\",\n",
    "                                    storage_key=odh_secret_name,\n",
    "                                    storage_path=in_bucket_path,\n",
    "                                    version=version_name,\n",
    "                                    description=\"demo20231121 e2e MNIST\",\n",
    "                                    )\n",
    "    print(\"RegisteredModel:\")\n",
    "    print(registry.get_registered_model(registeredmodel_name))\n",
    "    print(\"ModelVersion:\")\n",
    "    print(registry.get_model_version(registeredmodel_name, version_name))\n",
    "    print(\"ModelArtifact:\")\n",
    "    print(registry.get_model_artifact(registeredmodel_name, version_name))\n",
    "    return registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722467c-56fe-48fc-9f6c-989b8f97f73b",
   "metadata": {},
   "source": [
    "## Collect historical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5dea0-a038-4046-944d-eea2512169d8",
   "metadata": {},
   "source": [
    "Use SQL entity definition to collect all (`image_id`, `ts`) tuple from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b24a183-e4c2-48b8-a3e9-e952d1a76ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-04-10 07:02:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-10 07:02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-04-10 07:02:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-10 07:02:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-04-10 07:02:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id     event_timestamp\n",
       "0         5 2024-04-10 07:02:16\n",
       "1         0 2024-04-10 07:02:26\n",
       "2         4 2024-04-10 07:02:36\n",
       "3         1 2024-04-10 07:02:46\n",
       "4         9 2024-04-10 07:02:56"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all image_is, ts tuples\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{psqlUsername}:{psqlPassword}@{psqlHost}:{str(psqlPort)}/{psqlDb}')\n",
    "metadata = MetaData()\n",
    "table = Table(mnistTableName, metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "columns = [table.c.image_id, table.c.ts.label('event_timestamp')]\n",
    "stmt = select(columns)\n",
    "\n",
    "image_ids = []\n",
    "ts = []\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(stmt)\n",
    "    for row in result:\n",
    "        image_ids.append(row['image_id'])\n",
    "        ts.append(row['event_timestamp'])\n",
    "\n",
    "entity_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"image_id\": image_ids,\n",
    "        \"event_timestamp\": ts,\n",
    "    }\n",
    ")\n",
    "entity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec65b82-0017-453e-93da-8e20c89952e8",
   "metadata": {},
   "source": [
    "The execution of the following step that collects all the historical features for all the timestamps may take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180cc2ce-e042-43e3-8d3d-d3000fff3f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "store = FeatureStore(repo_path=os.environ['REPO_PATH'])    \n",
    "features = [f\"mnist:feature_{i+1}\" for i in range(28)]\n",
    "features.append(\"mnist:number\")\n",
    "historical_df = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=features,\n",
    ").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3b6ec-1dde-4c3b-99bc-3fa5176f0760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(historical_df)\n",
    "assert len(historical_df)==70000, f\"Found {len(historical_df)} instead of 70000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd900ac6-e9c6-42ba-a1c8-7da488806289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "historical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dcb232-e13f-4c0d-8f94-2e326e45f4a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "historical_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065eba2-3901-4b59-85e0-38a9cf1ea69a",
   "metadata": {},
   "source": [
    "## Prepara dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a2b10-5764-4bac-8077-78444942cfcc",
   "metadata": {},
   "source": [
    "Remove rows with null features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68bdbbe-d302-469b-bb28-c9b63bc051e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for id in range(28):\n",
    "    historical_df.dropna(subset=[f'feature_{id+1}'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f933f-a6c1-4920-b8e5-5cb6b3c5eb82",
   "metadata": {},
   "source": [
    "Rebuild the MNIST dataset.\n",
    "\n",
    "Goal is to recreate the `numpy` arrays that can feed the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f80b4f9-4c45-48a7-8831-20d9cc2ce486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf250f2-9114-4a0d-bd8c-c9f188115b34",
   "metadata": {},
   "source": [
    "Load features and revert column to rows.\n",
    "\n",
    "**Note**: `feature_N` columns contain string representation of `list<float>`, so they must be reverted to the original data types.\n",
    "\n",
    "The execution of these commands can take some minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fefc4ca-f35f-43cd-b027-b5d1da5c08fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index in range(len(historical_df)):\n",
    "    image_id = historical_df['image_id'].iloc[index]\n",
    "    # print(f'Rebuild {image_id} at index {index}')\n",
    "    image = [list(map(float, ast.literal_eval(\n",
    "        historical_df[f'feature_{id+1}'].iloc[index]))) for id in range(28)]\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eea7db-0da3-4cd1-97d6-fe635d185720",
   "metadata": {},
   "source": [
    "Extract the prediction column `number`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0286cd-0a52-45fc-8477-45e51da14d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for index in range(len(historical_df)):\n",
    "    numbers.append(int(historical_df['number'].iloc[index]))\n",
    "print(len(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c27e1f-ff95-4a3e-b06d-2551bf1966ff",
   "metadata": {},
   "source": [
    "Assign a fixed percentage of 20% to testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c05cd-7ea2-42d0-8a5a-43fc546d2599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = int(len(images) * 0.8)\n",
    "train_images = images[:split]\n",
    "test_images = images[split:]\n",
    "train_numbers = numbers[:split]\n",
    "test_numbers = numbers[split:]\n",
    "\n",
    "X_train = np.array(train_images)\n",
    "y_train = np.array(train_numbers)\n",
    "X_test = np.array(test_images)\n",
    "y_test = np.array(test_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac74d9b-a26e-425b-b949-ca1c82f26013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')\n",
    "print(f'y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c002a35-229c-4e09-a6b5-6012e8a22d47",
   "metadata": {},
   "source": [
    "Plot some data samples to validate the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa227793-ccb8-4f32-a26e-ffee9c4b48d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(9):  \n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4cf617-d3b7-4e85-8e38-45d18c66f6fd",
   "metadata": {},
   "source": [
    "## Train simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefdd195-e417-4322-9920-8dd861777353",
   "metadata": {},
   "source": [
    "Let's train a simple neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1404f63-2cbf-49fa-aa7a-be0cec6d9eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, model_name = simpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee6307-0136-4bc2-812e-00708ddf64fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d614f8-b276-47b4-b92d-529a398d7225",
   "metadata": {},
   "source": [
    "Evaluate model accuracy using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d54e3-6515-4d53-991d-41c915d3cd06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluateModelAccuracy(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98754564-e1c2-43a3-8e34-517b6ad53a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3133d-5d11-401e-9ec7-6693adc48214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testModelForSample(model, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76eb1b9-b1bd-4a78-917c-0ecc09d74d37",
   "metadata": {},
   "source": [
    "### Save the model as ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17985d6f-0059-4235-bf3b-096759ba3ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = saveModel(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c60c1e-8d71-4d61-821d-98847896b298",
   "metadata": {},
   "source": [
    "### Test the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d83f9-6853-48ad-9f38-4fe40dc4ea3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testModelFromFileForSample(file_name, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe1e6f3-d13d-4e90-92c9-c52539161e42",
   "metadata": {},
   "source": [
    "### Store the model to S3 compatible bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cadf91-711b-4aa1-9730-a9c403a29688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registeredmodel_name, version_name, odh_secret_name, in_bucket_path,in_bucket_target, full_bucket_target = storeTrainedModel(model, model_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d464104-1808-4a29-a206-ab8338bd556d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registeredmodel_name, version_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59e080-bfa8-463e-bcc0-403f2ab9b51e",
   "metadata": {},
   "source": [
    "### Register with Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495dff2e-e024-44c7-8381-ec7b2110da7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registerToModelRegistry(\n",
    "    registeredmodel_name, version_name, odh_secret_name, in_bucket_path,in_bucket_target, full_bucket_target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0362722-82b8-409f-b474-7f6e1974f529",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train a convoluted neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce509b30-e342-4cc3-8e51-4183ced0f43a",
   "metadata": {},
   "source": [
    "Let's train a an alternative, a convoluted neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98a57f-738d-457f-b496-166b065b5eae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, model_name = convolutedNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccae6b8-c4ef-4e42-8143-1cfae79279b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5640b02-f62e-4874-bceb-9b316984b0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluateModelAccuracy(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbcac3b-a394-4120-ba00-8fa94b731a60",
   "metadata": {},
   "source": [
    "### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58918931-682e-438a-b913-7ab12d2c1350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testModelForSample(model, 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa68f96-ad93-4ced-96e3-214e08650a89",
   "metadata": {},
   "source": [
    "### Save the model as ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934db90a-2f6d-4edd-aca5-26bf4c8f6d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = saveModel(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae766e-57f3-4e2e-8698-e5cd3db452bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testModelFromFileForSample(file_name, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea1079f-953f-4fd9-92f1-71ec1b46a4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registeredmodel_name, version_name, odh_secret_name, in_bucket_path,in_bucket_target, full_bucket_target = storeTrainedModel(model, model_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d2d8b5-1320-4344-8cc8-84c44b99e817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registry = registerToModelRegistry(\n",
    "    registeredmodel_name, version_name + \"1\", odh_secret_name, in_bucket_path,in_bucket_target, full_bucket_target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d658fb9-9c4c-498f-b966-0f0a5d8269ec",
   "metadata": {},
   "source": [
    "## Inspect Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25fb8c-f8f1-4cea-8b8f-65a6a3b97e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = registry._api.get_registered_models()\n",
    "assert len(models)==1, f\"Found {len(models)} instead of just 1\"\n",
    "registered_model = models[0]\n",
    "print(registered_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b317d3-f961-45b4-b1f2-febe483112df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility function to archive old versions\n",
    "# Uncomment and place the desired model version ids in the range() configuration \n",
    "# and the desired model id in the call to upsert_model_version()\n",
    "\n",
    "from model_registry.types import ContextState\n",
    "# for id in range(3,10):\n",
    "#     m = registry._api.get_model_version_by_id(id)\n",
    "#     if m != None:\n",
    "#         m.state=ContextState.ARCHIVED\n",
    "#         try:\n",
    "#             res = registry._api.upsert_model_version(m, 1)\n",
    "#         except Exception as e:\n",
    "#             print(f\"AlreadyExistsError for {id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f459d03-3078-43cf-b78a-9564c7a26402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registered_model_id = registered_model.id\n",
    "live_model_versions = [m for m in registry._api.get_model_versions(registered_model_id=registered_model_id) if m.state!=ContextState.ARCHIVED]\n",
    "assert len(live_model_versions)==2, f\"Found {len(live_model_versions)} instead of just 2\"\n",
    "\n",
    "for live_model_version in live_model_versions:\n",
    "    print(live_model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b6f9c-e281-4399-adcf-800be03a6182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
