{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9dc1a8-f4a2-484b-8c7a-0fb5a832a481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -q -r ../feast_modelregistry/requirements.txt\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b474a582-7347-4dd8-b5c7-a1b0c8516ff9",
   "metadata": {},
   "source": [
    "# Arrow Flight server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5af900-50d1-4a4e-90d9-d140062b1cc3",
   "metadata": {},
   "source": [
    "Mimics the behavior of the `feast serve_offline` CLI command:\n",
    "* Starts the server at port 8815\n",
    "* Connects the Feast repo in the MNIST demo folder\n",
    "* Implements the Arrow protocol to retrieve historical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c2b51-b53f-432b-9bd5-6c1fbe75efc4",
   "metadata": {},
   "source": [
    "## Constants and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5959d73-c72c-4e30-a2a3-fd77c485f9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env REPO_PATH=../feast_modelregistry/mnist_demo/feature_repo/\n",
    "import os\n",
    "os.environ['FEAST_USAGE'] = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cafea0-9d70-4dd4-8585-5c95a0a9dd91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import logging\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.flight\n",
    "\n",
    "from feast import FeatureStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e47a20-85f9-4252-8c2d-678f2eca6b1a",
   "metadata": {},
   "source": [
    "## Start Arrow Flight server\n",
    "\n",
    "**References**: Python examples from [Apache Arrow](https://github.com/apache/arrow/tree/main/python/examples/flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bb9c97-2a0c-4146-9e68-c32948965a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FlightServer(pa.flight.FlightServerBase):\n",
    "\n",
    "    def __init__(self, location=\"grpc://0.0.0.0:8815\",\n",
    "                 **kwargs):\n",
    "        super(FlightServer, self).__init__(location, **kwargs)\n",
    "        self._location = location\n",
    "        self.flights = {}\n",
    "        # INitializes the FeatureStore from the REPO_PATH path\n",
    "        self.store = FeatureStore(repo_path=os.environ['REPO_PATH'])\n",
    "\n",
    "    @classmethod\n",
    "    def descriptor_to_key(self, descriptor):\n",
    "        return (descriptor.descriptor_type.value, descriptor.command,\n",
    "                tuple(descriptor.path or tuple()))\n",
    "\n",
    "    # TODO: since we cannot anticipate here the call to get_historical_features call, what data should we return?\n",
    "    # ATM it returns the metadata of the \"entity_df\" table\n",
    "    def _make_flight_info(self, key, descriptor, params):\n",
    "        table = params['entity_df']\n",
    "        endpoints = [pyarrow.flight.FlightEndpoint(repr(key), [self._location])]\n",
    "        mock_sink = pyarrow.MockOutputStream()\n",
    "        stream_writer = pyarrow.RecordBatchStreamWriter(\n",
    "            mock_sink, table.schema)\n",
    "        stream_writer.write_table(table)\n",
    "        stream_writer.close()\n",
    "        data_size = mock_sink.size()\n",
    "\n",
    "        return pyarrow.flight.FlightInfo(table.schema,\n",
    "                                         descriptor, endpoints,\n",
    "                                         table.num_rows, data_size)\n",
    "\n",
    "    # Returns FlightDescriptor from the flights dictionary\n",
    "    def list_flights(self, context, criteria):\n",
    "        for key, table in self.flights.items():\n",
    "            if key[1] is not None:\n",
    "                descriptor = \\\n",
    "                    pyarrow.flight.FlightDescriptor.for_command(key[1])\n",
    "            else:\n",
    "                descriptor = pyarrow.flight.FlightDescriptor.for_path(*key[2])\n",
    "\n",
    "            yield self._make_flight_info(key, descriptor, table)\n",
    "\n",
    "    def get_flight_info(self, context, descriptor):\n",
    "        key = FlightServer.descriptor_to_key(descriptor)\n",
    "        if key in self.flights:\n",
    "            params = self.flights[key]\n",
    "            return self._make_flight_info(key, descriptor, params)\n",
    "        raise KeyError('Flight not found.')\n",
    "\n",
    "    # Expects to receive request parameters and stores them in the flights dictionary\n",
    "    # Indexed by the unique command\n",
    "    def do_put(self, context, descriptor, reader, writer):\n",
    "        key = FlightServer.descriptor_to_key(descriptor)\n",
    "\n",
    "        if key in self.flights:\n",
    "            params = self.flights[key]\n",
    "        else:\n",
    "            params = {}\n",
    "        decoded_metadata = {key.decode(): value.decode() for key, value in reader.schema.metadata.items()}\n",
    "        if 'command' in decoded_metadata:\n",
    "            command = decoded_metadata['command']\n",
    "            api = decoded_metadata['api']\n",
    "            param = decoded_metadata['param']\n",
    "            value = reader.read_all()\n",
    "            # Merge the existing dictionary for the same key, as we have multiple calls to do_put for the same key\n",
    "            params.update({'command': command, 'api': api, param: value})\n",
    "\n",
    "        self.flights[key] = params\n",
    "\n",
    "    # Extracts the API parameters from the flights dictionary, delegates the execution to the FeatureStore instance\n",
    "    # and returns the stream of data\n",
    "    def do_get(self, context, ticket):\n",
    "        key = ast.literal_eval(ticket.ticket.decode())\n",
    "        if key not in self.flights:\n",
    "            print(f\"Unknown key {key}\")\n",
    "            return None\n",
    "\n",
    "        api = self.flights[key]['api']\n",
    "        # print(f\"get key is {key}\")\n",
    "        # print(f\"requested api is {api}\")\n",
    "        if api == \"get_historical_features\":\n",
    "            # Extract parameters from the internal flight descriptor\n",
    "            entity_df_value = self.flights[key]['entity_df']\n",
    "            entity_df = pa.Table.to_pandas(entity_df_value)\n",
    "            # print(f\"entity_df is {entity_df}\")\n",
    "\n",
    "            features_value = self.flights[key]['features']\n",
    "            features = pa.RecordBatch.to_pylist(features_value)\n",
    "            features = [item['features'] for item in features]\n",
    "            # print(f\"features is {features}\")\n",
    "\n",
    "            print(f\"get_historical_features for: entity_df from {entity_df.index[0]} to {entity_df.index[len(entity_df)-1]}, \"\n",
    "                  f\"features from {features[0]} to {features[len(features)-1]}\")\n",
    "            training_df = self.store.get_historical_features(entity_df, features).to_df()\n",
    "            table = pa.Table.from_pandas(training_df)\n",
    "\n",
    "            # Get service is consumed, so we clear the corresponding flight\n",
    "            del self.flights[key]\n",
    "\n",
    "            return pa.flight.RecordBatchStream(table)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def list_actions(self, context):\n",
    "        return []\n",
    "\n",
    "    def do_action(self, context, action):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def do_drop_dataset(self, dataset):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c5081-4aa9-4ce5-a66f-26f025bb973b",
   "metadata": {},
   "source": [
    "**Note** Use `Interrupt the Kernel` button to stop the server (shortcut: `I,I`).\n",
    "\n",
    "If you encounter the `Address already in use` error, run `lsof -i :8815` from the Terminal and kill the process using the port. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea2674d-9ca5-41bb-b4c0-52a127ca657c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 12:32:24 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:24 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:24 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:24 INFO: Registry cache expired, so refreshing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_historical_features for: entity_df from 0 to 4999, features from {features[0]} to {features[len(features)-1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 12:32:25 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:26 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:26 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:26 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:26 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:26 INFO: Registry cache expired, so refreshing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_historical_features for: entity_df from 0 to 4999, features from {features[0]} to {features[len(features)-1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 12:32:27 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:27 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:27 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:27 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:27 INFO: Registry cache expired, so refreshing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_historical_features for: entity_df from 0 to 4999, features from {features[0]} to {features[len(features)-1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 12:32:28 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:28 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:28 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:28 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:28 INFO: Registry cache expired, so refreshing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_historical_features for: entity_df from 0 to 4999, features from {features[0]} to {features[len(features)-1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 12:32:30 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:30 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:30 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:30 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:30 INFO: Registry cache expired, so refreshing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_historical_features for: entity_df from 0 to 4999, features from {features[0]} to {features[len(features)-1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 12:32:31 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:31 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:31 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:31 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:31 INFO: Registry cache expired, so refreshing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_historical_features for: entity_df from 0 to 4999, features from {features[0]} to {features[len(features)-1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 12:32:32 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:32 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:32 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:32 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:32 INFO: Registry cache expired, so refreshing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_historical_features for: entity_df from 0 to 4999, features from {features[0]} to {features[len(features)-1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 12:32:33 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:33 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:33 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:33 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:34 INFO: Registry cache expired, so refreshing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_historical_features for: entity_df from 0 to 4999, features from {features[0]} to {features[len(features)-1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 12:32:35 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:35 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:35 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:35 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:35 INFO: Registry cache expired, so refreshing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_historical_features for: entity_df from 0 to 4999, features from {features[0]} to {features[len(features)-1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 12:32:36 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:36 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:36 INFO: Registry cache expired, so refreshing\n",
      "2024-05-08 12:32:36 INFO: Registry cache expired, so refreshing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_historical_features for: entity_df from 0 to 4999, features from {features[0]} to {features[len(features)-1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 12:32:36 INFO: Registry cache expired, so refreshing\n"
     ]
    }
   ],
   "source": [
    "LOG_FORMAT = \"%(asctime)s %(levelname)s: %(message)s\"\n",
    "DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=LOG_FORMAT,\n",
    "    datefmt=DATE_FORMAT,\n",
    ")\n",
    "server = FlightServer()\n",
    "logging.info(\"Started gRPC server\")\n",
    "server.serve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
